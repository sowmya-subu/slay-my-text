{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sowmya-subu/slay-my-text/blob/main/slaymytext_backend.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GN6WP4XoX9L6"
      },
      "outputs": [],
      "source": [
        "from getpass import getpass\n",
        "from huggingface_hub import login\n",
        "\n",
        "hf_token = getpass(\"Please enter your Hugging Face token:\")\n",
        "login(token=hf_token)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 1: Install dependencies\n",
        "!pip install -q bitsandbytes transformers accelerate\n",
        "\n",
        "# Step 2: Import necessary libraries\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "# Step 3: Load model and tokenizer\n",
        "model_name = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    device_map=\"auto\",              # Automatically use GPU if available\n",
        "    load_in_4bit=True,              # Efficient 4-bit quantization for free Colab GPU\n",
        "    torch_dtype=torch.float16\n",
        ")\n"
      ],
      "metadata": {
        "id": "i6_UpKhGh3QK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Define simple generation function\n",
        "def generate_genz_reword(text):\n",
        "    prompt = f\"<|system|>\\nYou are a playful, witty Gen Z content creator. Rewrite any input text using Gen Z slang, emojis, and humor while keeping the original meaning.\\n\\n<|user|>\\nRewrite the following text in a Gen Z tone: \\\"\" + text + \"\\\"\\n\\n<|assistant|>\"\n",
        "\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "    output = model.generate(**inputs, max_new_tokens=100, do_sample=True, temperature=0.7, top_p=0.9)\n",
        "    response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "    # Extract only the assistant's response part\n",
        "    genz_text = response.split('<|assistant|>')[-1].strip()\n",
        "\n",
        "    # Define basic unsafe words (expand as needed)\n",
        "    unsafe_words = [\"kill\", \"hate\", \"suicide\", \"violence\", \"racist\", \"sex\", \"murder\", \"abuse\"]\n",
        "\n",
        "    # Check for unsafe content\n",
        "    if any(word.lower() in genz_text.lower() for word in unsafe_words):\n",
        "        #log_unsafe(prompt, genz_text)\n",
        "        return \"‚ö†Ô∏è Sorry, I can't reword this text due to unsafe content.\"\n",
        "\n",
        "    return genz_text\n",
        "\n"
      ],
      "metadata": {
        "id": "GScEw_u8f-jl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Test it! Intermediate test\n",
        "sample_input = \"I'm looking forward to our meeting tomorrow. Let me know if you need anything beforehand.\"\n",
        "print(\"üé§ Original:\", sample_input)\n",
        "print(\"üéß Gen Z Style:\", generate_genz_reword(sample_input))\n"
      ],
      "metadata": {
        "id": "ct0AZ67xZDW6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Y2veerN_-ZT"
      },
      "outputs": [],
      "source": [
        "#Create Gradio webapp and launch demo live\n",
        "!pip install gradio --quiet\n",
        "import gradio as gr\n",
        "from datetime import datetime\n",
        "def capture_feedback(original, reworded, feedback, comment):\n",
        "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "    with open(\"feedback.txt\", \"a\") as f:\n",
        "        f.write(f\"Timestamp: {timestamp}\\n\")\n",
        "        f.write(f\"Original: {original}\\n\")\n",
        "        f.write(f\"Reworded: {reworded}\\n\")\n",
        "        f.write(f\"Feedback: {feedback}\\n\")\n",
        "    return \"‚úÖ Feedback saved!\"\n",
        "\n",
        "custom_theme = gr.themes.Soft(\n",
        "    primary_hue=\"indigo\",\n",
        "    secondary_hue=\"pink\",\n",
        "    font=[gr.themes.GoogleFont(\"Fugaz One\"), \"cursive\"],\n",
        "    radius_size=\"lg\", # Changed from \"xl\" to \"lg\"\n",
        "    spacing_size=\"lg\"\n",
        ")\n",
        "\n",
        "demo = gr.Interface(\n",
        "    fn=generate_genz_reword,\n",
        "    inputs=\"text\",\n",
        "    outputs=\"text\",\n",
        "    title=\"SlayMyText - Gen Z Rewording\",\n",
        "    description=\"Rewrite boring text into slay Gen Z speak\",\n",
        ")\n",
        "\n",
        "with gr.Blocks(theme=custom_theme) as demo:\n",
        "    gr.Markdown(\"## üé§ SlayMyText: Translate Anything to Gen Z üî•\")\n",
        "\n",
        "    with gr.Row():\n",
        "        input_text = gr.Textbox(lines=3, label=\"Enter Your Text\")\n",
        "        output_text = gr.Textbox(lines=3, label=\"Fire Text\")\n",
        "\n",
        "    run_btn = gr.Button(\"‚ú® Slay it, Don't Just Say it!\")\n",
        "\n",
        "    run_btn.click(fn=generate_genz_reword, inputs=input_text, outputs=output_text)\n",
        "\n",
        "    gr.Markdown(\"### üôè Did we slay it or nah?\")\n",
        "\n",
        "    with gr.Row():\n",
        "        feedback = gr.Radio(choices=[\"üî• Slayed\", \"Mid\"], label=\"Your Reaction\")\n",
        "        comment = gr.Textbox(lines=2, label=\"Optional Comments (e.g., why it's mid)\")\n",
        "        submit_btn = gr.Button(\"Submit Feedback\")\n",
        "        status = gr.Textbox(label=\"\", interactive=False)\n",
        "\n",
        "    submit_btn.click(fn=capture_feedback,\n",
        "                 inputs=[input_text, output_text, feedback, comment],\n",
        "                 outputs=status)\n",
        "\n",
        "demo.launch()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TGzCCcz3AAPJ"
      },
      "outputs": [],
      "source": [
        "#additional functions to be developed for limiting rate of requests\n",
        "import time\n",
        "\n",
        "last_request_time = 0\n",
        "\n",
        "def rate_limited_slay(text):\n",
        "    global last_request_time\n",
        "    if time.time() - last_request_time < 10:  # 10-second delay\n",
        "        return \"Please wait a few seconds between rewordings.\"\n",
        "    last_request_time = time.time()\n",
        "    return slay_my_text(text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nS0-GwukAPgy"
      },
      "outputs": [],
      "source": [
        "UNSAFE_KEYWORDS = [\"kill\", \"suicide\", \"hate\", \"racist\"]\n",
        "\n",
        "def safe_response(text):\n",
        "    for word in UNSAFE_KEYWORDS:\n",
        "        if word in text.lower():\n",
        "            return \"‚ö†Ô∏è Content was flagged as unsafe. Please try a different input.\"\n",
        "    return text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "35PSbPqdASN0"
      },
      "outputs": [],
      "source": [
        "def slay_safe(text):\n",
        "    response = rate_limited_slay(text)\n",
        "    return safe_response(response)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMfxJTmzNmJsJ+7dt7JeOrm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}